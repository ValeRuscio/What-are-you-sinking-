{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dfa674",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35696e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import gc\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import traceback\n",
    "import warnings\n",
    "import scipy.stats as stats\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers import BitsAndBytesConfig\n",
    "import bitsandbytes as bnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e8dac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "class ReferencePointAnalysis:\n",
    "    \"\"\"\n",
    "    Analyzes how reference points affect value vector transformations in transformer models.\n",
    "    This analysis tracks the influence of reference tokens versus non-reference tokens\n",
    "    on the transformation of value vectors in self-attention mechanisms.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model_name, output_dir=\"./reference_point_analysis\"):\n",
    "        \"\"\"Initialize the analysis with model name and output directory.\"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.output_dir = output_dir\n",
    "        self.model = None\n",
    "        self.tokenizer = None\n",
    "        self.results = {}\n",
    "\n",
    "        self.hidden_states = None\n",
    "        self.attention_matrices = None\n",
    "\n",
    "        # Parameters for reference point identification\n",
    "        self.reference_threshold = 0.1  # Threshold for identifying reference tokens\n",
    "\n",
    "        self.debug = True\n",
    "\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    def load_model(self, use_4bit=True):\n",
    "        \"\"\"Load the model and tokenizer with robust error handling.\"\"\"\n",
    "        print(f\"Loading model: {self.model_name}\")\n",
    "\n",
    "        try:\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(self.model_name, trust_remote_code=True)\n",
    "\n",
    "            # Check if we should try 4-bit quantization\n",
    "            if use_4bit:\n",
    "                try:\n",
    "                    quantization_config = BitsAndBytesConfig(\n",
    "                        load_in_4bit=True,\n",
    "                        bnb_4bit_compute_dtype=torch.float16\n",
    "                    )\n",
    "\n",
    "                    self.model = AutoModelForCausalLM.from_pretrained(\n",
    "                        self.model_name,\n",
    "                        torch_dtype=torch.float16,\n",
    "                        quantization_config=quantization_config,\n",
    "                        device_map=\"auto\",\n",
    "                        trust_remote_code=True,\n",
    "                        output_hidden_states=True\n",
    "                    )\n",
    "                    print(\"Model loaded with 4-bit quantization\")\n",
    "                except (ImportError, ModuleNotFoundError) as e:\n",
    "                    print(f\"BitsAndBytes not available: {e}\")\n",
    "                    print(\"Falling back to standard loading...\")\n",
    "                    self.model = AutoModelForCausalLM.from_pretrained(\n",
    "                        self.model_name,\n",
    "                        torch_dtype=torch.float16,\n",
    "                        device_map=\"auto\",\n",
    "                        trust_remote_code=True,\n",
    "                        output_hidden_states=True\n",
    "                    )\n",
    "            else:\n",
    "                self.model = AutoModelForCausalLM.from_pretrained(\n",
    "                    self.model_name,\n",
    "                    torch_dtype=torch.float16,\n",
    "                    device_map=\"auto\",\n",
    "                    trust_remote_code=True,\n",
    "                    output_hidden_states=True\n",
    "                )\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model: {e}\")\n",
    "            print(\"This might be due to an unsupported model architecture or outdated transformers library.\")\n",
    "            print(\"Try updating with: pip install --upgrade transformers\")\n",
    "            print(\"Or install from source: pip install git+https://github.com/huggingface/transformers.git\")\n",
    "            print(\"Using a fallback approach...\")\n",
    "            return None, None\n",
    "\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        print(f\"Model loaded successfully\")\n",
    "        return self.model, self.tokenizer\n",
    "\n",
    "    def identify_reference_tokens(self, attention_matrix, threshold=None):\n",
    "        \"\"\"\n",
    "        Identify reference tokens based on attention patterns, with improved robustness.\n",
    "        A token is considered a reference token if it receives above-threshold\n",
    "        attention from a significant proportion of other tokens.\n",
    "\n",
    "        Args:\n",
    "            attention_matrix: numpy array of shape (seq_len, seq_len)\n",
    "            threshold: float, threshold for identifying reference tokens\n",
    "\n",
    "        Returns:\n",
    "            list of indices of reference tokens\n",
    "        \"\"\"\n",
    "        if threshold is None:\n",
    "            threshold = self.reference_threshold\n",
    "\n",
    "        # Handle NaN/Inf in attention matrix\n",
    "        attn_clean = np.nan_to_num(attention_matrix, nan=0.0, posinf=1.0, neginf=0.0)\n",
    "\n",
    "        # Calculate the average attention received by each token\n",
    "        avg_attention_received = np.mean(attn_clean, axis=0)\n",
    "\n",
    "        # Identify tokens that receive attention above the threshold\n",
    "        reference_tokens = np.where(avg_attention_received > threshold)[0]\n",
    "\n",
    "        # If no reference tokens found with this threshold, take the top 10%\n",
    "        if len(reference_tokens) == 0:\n",
    "            num_tokens = attention_matrix.shape[0]\n",
    "            top_n = max(1, int(0.1 * num_tokens))  # At least 1 token\n",
    "            reference_tokens = np.argsort(avg_attention_received)[-top_n:]\n",
    "\n",
    "        # max 30% of sequence\n",
    "        max_ref_tokens = max(1, int(0.3 * attention_matrix.shape[0]))\n",
    "        if len(reference_tokens) > max_ref_tokens:\n",
    "            # Keep only the top reference tokens\n",
    "            sorted_indices = np.argsort(avg_attention_received[reference_tokens])\n",
    "            reference_tokens = reference_tokens[sorted_indices[-max_ref_tokens:]]\n",
    "\n",
    "        if self.debug:\n",
    "            print(f\"Identified {len(reference_tokens)} reference tokens out of {attention_matrix.shape[0]} total tokens\")\n",
    "\n",
    "        return reference_tokens.tolist()\n",
    "\n",
    "    def extract_value_vectors(self, hidden_states, layer_idx):\n",
    "        \"\"\"\n",
    "        Extract value vectors for a specific layer.\n",
    "        This is a modified version that correctly handles the hidden states format\n",
    "        from different model architectures.\n",
    "\n",
    "        Args:\n",
    "            hidden_states: list of tensors, hidden states for each layer\n",
    "            layer_idx: int, index of the layer\n",
    "\n",
    "        Returns:\n",
    "            numpy array of value vectors with shape (seq_len, hidden_dim)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            layer_hidden = hidden_states[layer_idx]\n",
    "\n",
    "            if isinstance(layer_hidden, torch.Tensor):\n",
    "                layer_hidden = layer_hidden.cpu().numpy()\n",
    "\n",
    "            # Expected shape: (batch_size, seq_len, hidden_dim)\n",
    "            if self.debug:\n",
    "                print(f\"Hidden state shape: {layer_hidden.shape}\")\n",
    "\n",
    "            # Handle different shape formats\n",
    "            if len(layer_hidden.shape) == 3:\n",
    "                if layer_hidden.shape[0] == 1:  # (batch_size, seq_len, hidden_dim)\n",
    "                    result = layer_hidden[0]  # Return (seq_len, hidden_dim)\n",
    "                elif layer_hidden.shape[1] == 1:  # (seq_len, batch_size, hidden_dim)\n",
    "                    result = layer_hidden[:, 0, :]  # Return (seq_len, hidden_dim)\n",
    "                else:\n",
    "                    # If batch dimension is neither 0 nor 1, use the first batch\n",
    "                    result = layer_hidden[0]  # Assume (batch_size, seq_len, hidden_dim)\n",
    "            elif len(layer_hidden.shape) == 2:\n",
    "                # Already in the format (seq_len, hidden_dim)\n",
    "                result = layer_hidden\n",
    "            else:\n",
    "                raise ValueError(f\"Unexpected hidden state shape: {layer_hidden.shape}\")\n",
    "\n",
    "            result = np.nan_to_num(result, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "            # Check for extreme values and scale if necessary\n",
    "            max_abs = np.max(np.abs(result))\n",
    "            if max_abs > 1e5:\n",
    "                # Scale down to prevent overflow\n",
    "                scale_factor = 1e5 / max_abs\n",
    "                result = result * scale_factor\n",
    "\n",
    "            return result\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error in extract_value_vectors: {e}\")\n",
    "            traceback.print_exc()\n",
    "            return np.zeros((1, 1))\n",
    "\n",
    "    def decompose_value_transformations(self, value_vectors, attention_matrix, reference_tokens):\n",
    "        \"\"\"\n",
    "        Decompose value vector transformations into components from reference\n",
    "        and non-reference tokens. Improved for numerical stability.\n",
    "\n",
    "        Args:\n",
    "            value_vectors: numpy array of value vectors with shape (seq_len, hidden_dim)\n",
    "            attention_matrix: numpy array of attention weights with shape (seq_len, seq_len)\n",
    "            reference_tokens: list of indices of reference tokens\n",
    "\n",
    "        Returns:\n",
    "            dict with decomposition metrics\n",
    "        \"\"\"\n",
    "        if self.debug:\n",
    "            print(f\"Value vectors shape: {value_vectors.shape}\")\n",
    "            print(f\"Attention matrix shape: {attention_matrix.shape}\")\n",
    "            print(f\"Number of reference tokens: {len(reference_tokens)}\")\n",
    "\n",
    "        # Handle case where dimensions don't match\n",
    "        seq_len = attention_matrix.shape[0]\n",
    "        if value_vectors.shape[0] != seq_len:\n",
    "            print(f\"WARNING: Value vectors seq_len ({value_vectors.shape[0]}) doesn't match attention matrix seq_len ({seq_len})\")\n",
    "            print(\"Using a simplified approach...\")\n",
    "\n",
    "            metrics = {\n",
    "                \"relative_magnitude\": [0.5] * seq_len,\n",
    "                \"directional_influence\": [0.5] * seq_len,\n",
    "                \"information_content_change\": [0.0] * seq_len\n",
    "            }\n",
    "            return metrics\n",
    "\n",
    "        attention_matrix = np.nan_to_num(attention_matrix, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "        # Normalize attention matrices if needed\n",
    "        row_sums = np.sum(attention_matrix, axis=1, keepdims=True)\n",
    "        mask = row_sums > 1e-10  # Create a mask for rows with non-zero sums\n",
    "        attention_matrix = np.where(mask, attention_matrix / np.maximum(row_sums, 1e-10), 0.0)\n",
    "\n",
    "        metrics = {\n",
    "            \"relative_magnitude\": [],\n",
    "            \"directional_influence\": [],\n",
    "            \"information_content_change\": []\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            for i in range(seq_len):\n",
    "                # Skip if this is a reference token itself\n",
    "                if i in reference_tokens:\n",
    "                    # Add dummy values for reference tokens\n",
    "                    metrics[\"relative_magnitude\"].append(0.5)\n",
    "                    metrics[\"directional_influence\"].append(0.5)\n",
    "                    metrics[\"information_content_change\"].append(0.0)\n",
    "                    continue\n",
    "\n",
    "                # Create sets for cleaner indexing\n",
    "                ref_set = set(reference_tokens)\n",
    "                non_ref_set = set(range(seq_len)) - ref_set\n",
    "\n",
    "                # Convert to lists for indexing\n",
    "                ref_indices = list(ref_set)\n",
    "                non_ref_indices = list(non_ref_set)\n",
    "\n",
    "                # Get attention weights for this token\n",
    "                attn_weights_i = attention_matrix[i]\n",
    "\n",
    "                # Calculate the post-attention hidden state\n",
    "                post_attn_i = np.zeros_like(value_vectors[0])\n",
    "                attn_sum = 0.0  # Track total attention weight\n",
    "                for j in range(seq_len):\n",
    "                    if j < value_vectors.shape[0]:\n",
    "                        # Handle NaN or inf in attention weights\n",
    "                        weight = attn_weights_i[j]\n",
    "                        if np.isnan(weight) or np.isinf(weight):\n",
    "                            weight = 0.0\n",
    "                        attn_sum += weight\n",
    "                        post_attn_i += weight * value_vectors[j]\n",
    "\n",
    "                # Normalize if total attention weight is too small\n",
    "                if attn_sum < 1e-10:\n",
    "                    post_attn_i = np.zeros_like(value_vectors[0])\n",
    "\n",
    "                # Calculate reference contribution\n",
    "                ref_contribution = np.zeros_like(value_vectors[0])\n",
    "                ref_attn_sum = 0.0\n",
    "                for j in ref_indices:\n",
    "                    if j < value_vectors.shape[0]:\n",
    "                        weight = attn_weights_i[j]\n",
    "                        if np.isnan(weight) or np.isinf(weight):\n",
    "                            weight = 0.0\n",
    "                        ref_attn_sum += weight\n",
    "                        ref_contribution += weight * value_vectors[j]\n",
    "\n",
    "                # Calculate non-reference contribution\n",
    "                non_ref_contribution = np.zeros_like(value_vectors[0])\n",
    "                non_ref_attn_sum = 0.0\n",
    "                for j in non_ref_indices:\n",
    "                    if j < value_vectors.shape[0]:\n",
    "                        weight = attn_weights_i[j]\n",
    "                        if np.isnan(weight) or np.isinf(weight):\n",
    "                            weight = 0.0\n",
    "                        non_ref_attn_sum += weight\n",
    "                        non_ref_contribution += weight * value_vectors[j]\n",
    "\n",
    "                # 1. Relative Magnitude \n",
    "                ref_norm = np.linalg.norm(ref_contribution)\n",
    "                total_norm = np.linalg.norm(post_attn_i)\n",
    "\n",
    "                # Handle zero or very small norms\n",
    "                if total_norm < 1e-10:\n",
    "                    rel_mag = 0.0 if ref_norm < 1e-10 else 1.0\n",
    "                else:\n",
    "                    rel_mag = float(np.clip(ref_norm / total_norm, 0.0, 1.0))\n",
    "\n",
    "                # 2. Directional Influence \n",
    "                if ref_norm < 1e-10 or total_norm < 1e-10:\n",
    "                    ref_dir = 0.5  \n",
    "                else:\n",
    "                    # Safe dot product with clipping\n",
    "                    dot_prod = np.dot(ref_contribution, post_attn_i)\n",
    "                    ref_dir = float(np.clip(dot_prod / (ref_norm * total_norm), -1.0, 1.0))\n",
    "                    # Scale from [-1,1] to [0,1] for consistency\n",
    "                    ref_dir = (ref_dir + 1.0) / 2.0\n",
    "\n",
    "                # 3. Information Content Change - L2 calculation\n",
    "                diff_vector = post_attn_i - non_ref_contribution\n",
    "                squared_sum = 0.0\n",
    "                for val in diff_vector:\n",
    "                    # Avoid overflow by handling each component carefully\n",
    "                    val_safe = 0.0 if np.isnan(val) or np.isinf(val) else val\n",
    "                    squared_sum += float(val_safe) * float(val_safe)\n",
    "                info_change = float(np.sqrt(max(0.0, squared_sum)))\n",
    "\n",
    "                # Normalize information content change to a reasonable range\n",
    "                if info_change > 1e6:\n",
    "                    info_change = 1e6  # Cap extremely large values\n",
    "\n",
    "                # NaN/Inf\n",
    "                rel_mag = 0.5 if np.isnan(rel_mag) or np.isinf(rel_mag) else rel_mag\n",
    "                ref_dir = 0.5 if np.isnan(ref_dir) or np.isinf(ref_dir) else ref_dir\n",
    "                info_change = 0.0 if np.isnan(info_change) or np.isinf(info_change) else info_change\n",
    "\n",
    "                # Store metrics\n",
    "                metrics[\"relative_magnitude\"].append(float(rel_mag))\n",
    "                metrics[\"directional_influence\"].append(float(ref_dir))\n",
    "                metrics[\"information_content_change\"].append(float(info_change))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error in decompose_value_transformations: {e}\")\n",
    "            traceback.print_exc()\n",
    "\n",
    "            metrics = {\n",
    "                \"relative_magnitude\": [0.5] * seq_len,\n",
    "                \"directional_influence\": [0.5] * seq_len,\n",
    "                \"information_content_change\": [0.0] * seq_len\n",
    "            }\n",
    "\n",
    "        return metrics\n",
    "\n",
    "    def safe_mean(self, values):\n",
    "        \"\"\"Calculate mean safely, avoiding NaN results.\"\"\"\n",
    "        if not values:\n",
    "            return 0.0\n",
    "        # Filter out NaN and Inf values\n",
    "        clean_values = [v for v in values if not np.isnan(v) and not np.isinf(v)]\n",
    "        if not clean_values:\n",
    "            return 0.0\n",
    "        return float(np.mean(clean_values))\n",
    "\n",
    "    def sanitize_metrics(self, metrics_dict):\n",
    "        \"\"\"Replace NaN/Inf values with defaults.\"\"\"\n",
    "        for metric_name, values in metrics_dict.items():\n",
    "            if isinstance(values, list):\n",
    "                metrics_dict[metric_name] = [\n",
    "                    0.5 if (np.isnan(v) or np.isinf(v)) and metric_name != \"information_content_change\"\n",
    "                    else 0.0 if (np.isnan(v) or np.isinf(v))\n",
    "                    else float(v) for v in values\n",
    "                ]\n",
    "        return metrics_dict\n",
    "\n",
    "    def analyze_text(self, text):\n",
    "        \"\"\"\n",
    "        Analyze a text sample and compute metrics for reference point influence.\n",
    "        \"\"\"\n",
    "        if self.model is None or self.tokenizer is None:\n",
    "            print(\"Model or tokenizer not loaded!\")\n",
    "            return {\"error\": \"Model or tokenizer not loaded\"}\n",
    "\n",
    "        try:\n",
    "            if self.debug:\n",
    "                print(f\"Analyzing text: '{text[:50]}...'\")\n",
    "\n",
    "            inputs = self.tokenizer(text, return_tensors=\"pt\").to(self.model.device)\n",
    "\n",
    "            if self.debug:\n",
    "                print(f\"Tokenized input shape: {inputs.input_ids.shape}\")\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(\n",
    "                    **inputs,\n",
    "                    output_attentions=True,\n",
    "                    output_hidden_states=True,\n",
    "                    return_dict=True\n",
    "                )\n",
    "\n",
    "            # Extract attention patterns and hidden states\n",
    "            attentions = outputs.attentions  # tuple of (layer, batch, head, seq_len, seq_len)\n",
    "            hidden_states = outputs.hidden_states  # tuple of (layer+1, batch, seq_len, hidden_dim)\n",
    "\n",
    "            if self.debug:\n",
    "                print(f\"Number of attention layers: {len(attentions)}\")\n",
    "                print(f\"Number of hidden state layers: {len(hidden_states)}\")\n",
    "                if len(attentions) > 0:\n",
    "                    print(f\"Attention shape for first layer: {attentions[0].shape}\")\n",
    "                if len(hidden_states) > 0:\n",
    "                    print(f\"Hidden state shape for first layer: {hidden_states[0].shape}\")\n",
    "\n",
    "            self.attention_matrices = attentions\n",
    "            self.hidden_states = hidden_states\n",
    "\n",
    "            results = {\n",
    "                \"layers\": {}\n",
    "            }\n",
    "\n",
    "            # Process each layer\n",
    "            num_layers = len(attentions)\n",
    "            for layer_idx in range(num_layers):\n",
    "                if self.debug:\n",
    "                    print(f\"Processing layer {layer_idx+1}/{num_layers}\")\n",
    "\n",
    "                # Each layer has shape (batch, head, seq_len, seq_len)\n",
    "                layer_attention = attentions[layer_idx][0].cpu().numpy()  # shape: (head, seq_len, seq_len)\n",
    "\n",
    "                # Compute average attention pattern across all heads\n",
    "                avg_attention = np.mean(layer_attention, axis=0)\n",
    "\n",
    "                # Clean any NaN values\n",
    "                avg_attention = np.nan_to_num(avg_attention, nan=0.0, posinf=1.0, neginf=0.0)\n",
    "\n",
    "                if self.debug:\n",
    "                    print(f\"Average attention shape: {avg_attention.shape}\")\n",
    "\n",
    "                # Extract value vectors for this layer\n",
    "                value_vectors = self.extract_value_vectors(hidden_states, layer_idx)\n",
    "\n",
    "                if self.debug:\n",
    "                    print(f\"Value vectors shape: {value_vectors.shape}\")\n",
    "\n",
    "                # Identify reference tokens\n",
    "                reference_tokens = self.identify_reference_tokens(avg_attention)\n",
    "\n",
    "                # Decompose value transformations\n",
    "                decomposition_metrics = self.decompose_value_transformations(\n",
    "                    value_vectors, avg_attention, reference_tokens\n",
    "                )\n",
    "\n",
    "                decomposition_metrics = self.sanitize_metrics(decomposition_metrics)\n",
    "\n",
    "                results[\"layers\"][str(layer_idx)] = {\n",
    "                    \"reference_tokens\": reference_tokens,\n",
    "                    \"num_reference_tokens\": len(reference_tokens),\n",
    "                    \"metrics\": decomposition_metrics\n",
    "                }\n",
    "\n",
    "            return results\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error analyzing text: {e}\")\n",
    "            traceback.print_exc()\n",
    "            return {\"error\": str(e)}\n",
    "\n",
    "    def analyze_samples(self, texts, max_failures=20):\n",
    "        \"\"\"\n",
    "        Analyze multiple text samples and collect metrics for correlation analysis.\n",
    "\n",
    "        Args:\n",
    "            texts: list of text samples\n",
    "            max_failures: maximum number of consecutive failures before giving up\n",
    "        \"\"\"\n",
    "        print(f\"Analyzing {len(texts)} text samples...\")\n",
    "\n",
    "        if self.model is None:\n",
    "            self.load_model()\n",
    "\n",
    "        metric_collectors = {\n",
    "            \"relative_magnitude\": {},\n",
    "            \"directional_influence\": {},\n",
    "            \"information_content_change\": {},\n",
    "            \"reference_token_count\": {}\n",
    "        }\n",
    "\n",
    "        successful_analyses = 0\n",
    "        consecutive_failures = 0\n",
    "\n",
    "        for i, text in enumerate(tqdm(texts, desc=\"Processing texts\")):\n",
    "            try:\n",
    "                result = self.analyze_text(text)\n",
    "\n",
    "                if \"error\" in result:\n",
    "                    consecutive_failures += 1\n",
    "                    if consecutive_failures >= max_failures:\n",
    "                        print(f\"Too many consecutive failures ({max_failures}). Stopping analysis.\")\n",
    "                        break\n",
    "                    continue\n",
    "\n",
    "                # Reset consecutive failures counter\n",
    "                consecutive_failures = 0\n",
    "                successful_analyses += 1\n",
    "\n",
    "                # Collect metrics from each layer\n",
    "                for layer_idx, layer_data in result[\"layers\"].items():\n",
    "                    if layer_idx not in metric_collectors[\"relative_magnitude\"]:\n",
    "                        # Initialize layer collectors for all metrics\n",
    "                        for metric in metric_collectors.keys():\n",
    "                            metric_collectors[metric][layer_idx] = []\n",
    "\n",
    "                    metric_collectors[\"reference_token_count\"][layer_idx].append(\n",
    "                        layer_data[\"num_reference_tokens\"]\n",
    "                    )\n",
    "\n",
    "                    for metric_name, values in layer_data[\"metrics\"].items():\n",
    "                        avg_value = self.safe_mean(values)\n",
    "                        metric_collectors[metric_name][layer_idx].append(avg_value)\n",
    "\n",
    "                torch.cuda.empty_cache()\n",
    "                gc.collect()\n",
    "\n",
    "                # Progress indication\n",
    "                if (i+1) % 5 == 0:\n",
    "                    print(f\"Processed {i+1}/{len(texts)} samples\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error analyzing text {i+1}: {str(e)}\")\n",
    "                traceback.print_exc()\n",
    "                consecutive_failures += 1\n",
    "                if consecutive_failures >= max_failures:\n",
    "                    print(f\"Too many consecutive failures ({max_failures}). Stopping analysis.\")\n",
    "                    break\n",
    "\n",
    "        print(f\"Successfully analyzed {successful_analyses}/{len(texts)} samples\")\n",
    "\n",
    "        if successful_analyses > 0:\n",
    "            stats_results = self.compute_statistics(metric_collectors)\n",
    "\n",
    "            self.results = {\n",
    "                \"metric_collectors\": metric_collectors,\n",
    "                \"statistics\": stats_results,\n",
    "                \"successful_analyses\": successful_analyses\n",
    "            }\n",
    "\n",
    "            return stats_results\n",
    "        else:\n",
    "            print(\"No successful analyses to compute statistics\")\n",
    "            return {}\n",
    "\n",
    "    def safe_correlation(self, x, y):\n",
    "        \"\"\"Calculate correlation safely, avoiding NaN results.\"\"\"\n",
    "        if len(x) < 3 or len(y) < 3:\n",
    "            return 0.0\n",
    "\n",
    "        std_x = np.std(x)\n",
    "        std_y = np.std(y)\n",
    "\n",
    "        if std_x < 1e-8 or std_y < 1e-8:\n",
    "            return 0.0  # Not enough variance for meaningful correlation\n",
    "\n",
    "        try:\n",
    "            corr = np.corrcoef(x, y)[0, 1]\n",
    "            # Handle NaN/Inf\n",
    "            if np.isnan(corr) or np.isinf(corr):\n",
    "                return 0.0\n",
    "            return float(corr)\n",
    "        except Exception:\n",
    "            return 0.0  # Return zero correlation on any error\n",
    "\n",
    "    def safe_trend_analysis(self, indices, values):\n",
    "        \"\"\"Calculate trend correlation safely.\"\"\"\n",
    "        if len(indices) < 2 or len(values) < 2:\n",
    "            return {\"correlation\": 0.0, \"pattern\": \"unknown\"}\n",
    "\n",
    "        # Check for constant values (no variance)\n",
    "        if np.all(np.array(values) == values[0]):\n",
    "            return {\"correlation\": 0.0, \"pattern\": \"constant\"}\n",
    "\n",
    "        try:\n",
    "            # Use Spearman rank correlation for trend\n",
    "            trend_corr, _ = stats.spearmanr(indices, values)\n",
    "\n",
    "            # Handle NaN or Inf\n",
    "            if np.isnan(trend_corr) or np.isinf(trend_corr):\n",
    "                return {\"correlation\": 0.0, \"pattern\": \"unknown\"}\n",
    "\n",
    "            pattern = \"increasing\" if trend_corr > 0.5 else (\"decreasing\" if trend_corr < -0.5 else \"mixed\")\n",
    "            return {\"correlation\": float(trend_corr), \"pattern\": pattern}\n",
    "        except Exception:\n",
    "            return {\"correlation\": 0.0, \"pattern\": \"unknown\"}\n",
    "\n",
    "    def compute_statistics(self, metric_collectors):\n",
    "        \"\"\"\n",
    "        Compute statistics and correlations for the collected metrics.\n",
    "        Improved for numerical stability with added significance testing.\n",
    "        \"\"\"\n",
    "        print(\"Computing statistics...\")\n",
    "\n",
    "        stats_results = {\n",
    "            \"by_layer\": {},\n",
    "            \"overall\": {}\n",
    "        }\n",
    "\n",
    "        metrics = [\"relative_magnitude\", \"directional_influence\", \"information_content_change\"]\n",
    "\n",
    "        all_rel_mag = []\n",
    "        all_dir_inf = []\n",
    "        all_info_change = []\n",
    "        all_ref_counts = []\n",
    "\n",
    "        for layer_idx in metric_collectors[\"relative_magnitude\"].keys():\n",
    "            stats_results[\"by_layer\"][layer_idx] = {}\n",
    "\n",
    "            # Collect layer metrics\n",
    "            rel_mag = metric_collectors[\"relative_magnitude\"][layer_idx]\n",
    "            dir_inf = metric_collectors[\"directional_influence\"][layer_idx]\n",
    "            info_change = metric_collectors[\"information_content_change\"][layer_idx]\n",
    "            ref_counts = metric_collectors[\"reference_token_count\"][layer_idx]\n",
    "\n",
    "            if not rel_mag:\n",
    "                continue\n",
    "\n",
    "            # Clean metrics of any remaining NaN or Inf values\n",
    "            rel_mag = [v for v in rel_mag if not np.isnan(v) and not np.isinf(v)]\n",
    "            dir_inf = [v for v in dir_inf if not np.isnan(v) and not np.isinf(v)]\n",
    "            info_change = [v for v in info_change if not np.isnan(v) and not np.isinf(v)]\n",
    "            ref_counts = [v for v in ref_counts if not np.isnan(v) and not np.isinf(v)]\n",
    "\n",
    "            # Extend overall metrics\n",
    "            all_rel_mag.extend(rel_mag)\n",
    "            all_dir_inf.extend(dir_inf)\n",
    "            all_info_change.extend(info_change)\n",
    "            all_ref_counts.extend(ref_counts)\n",
    "\n",
    "            # Calculate basic statistics for each metric in this layer\n",
    "            layer_stats = {}\n",
    "\n",
    "            # Process relative magnitude\n",
    "            if len(rel_mag) >= 1:\n",
    "                layer_stats[\"relative_magnitude\"] = {\n",
    "                    \"mean\": float(np.mean(rel_mag)),\n",
    "                    \"median\": float(np.median(rel_mag)),\n",
    "                    \"std\": float(np.std(rel_mag)) if len(rel_mag) > 1 else 0.0,\n",
    "                    \"min\": float(np.min(rel_mag)),\n",
    "                    \"max\": float(np.max(rel_mag))\n",
    "                }\n",
    "\n",
    "            # Process directional influence\n",
    "            if len(dir_inf) >= 1:\n",
    "                layer_stats[\"directional_influence\"] = {\n",
    "                    \"mean\": float(np.mean(dir_inf)),\n",
    "                    \"median\": float(np.median(dir_inf)),\n",
    "                    \"std\": float(np.std(dir_inf)) if len(dir_inf) > 1 else 0.0,\n",
    "                    \"min\": float(np.min(dir_inf)),\n",
    "                    \"max\": float(np.max(dir_inf))\n",
    "                }\n",
    "\n",
    "            # Process information content change\n",
    "            if len(info_change) >= 1:\n",
    "                layer_stats[\"information_content_change\"] = {\n",
    "                    \"mean\": float(np.mean(info_change)),\n",
    "                    \"median\": float(np.median(info_change)),\n",
    "                    \"std\": float(np.std(info_change)) if len(info_change) > 1 else 0.0,\n",
    "                    \"min\": float(np.min(info_change)),\n",
    "                    \"max\": float(np.max(info_change))\n",
    "                }\n",
    "\n",
    "            # Process reference token counts\n",
    "            if len(ref_counts) >= 1:\n",
    "                layer_stats[\"reference_token_count\"] = {\n",
    "                    \"mean\": float(np.mean(ref_counts)),\n",
    "                    \"median\": float(np.median(ref_counts)),\n",
    "                    \"std\": float(np.std(ref_counts)) if len(ref_counts) > 1 else 0.0,\n",
    "                    \"min\": float(np.min(ref_counts)),\n",
    "                    \"max\": float(np.max(ref_counts))\n",
    "                }\n",
    "\n",
    "            # Calculate correlations between metrics \n",
    "            if len(rel_mag) >= 3 and len(dir_inf) >= 3:\n",
    "                corr_val = self.safe_correlation(rel_mag, dir_inf)\n",
    "                layer_stats[\"corr_rel_mag_dir_inf\"] = corr_val\n",
    "\n",
    "                # Add significance test for correlation\n",
    "                try:\n",
    "                    _, p_value = stats.pearsonr(rel_mag, dir_inf)\n",
    "                    layer_stats[\"corr_rel_mag_dir_inf_pvalue\"] = float(p_value)\n",
    "                    layer_stats[\"corr_rel_mag_dir_inf_significant\"] = p_value < 0.05\n",
    "                except:\n",
    "                    layer_stats[\"corr_rel_mag_dir_inf_pvalue\"] = 1.0\n",
    "                    layer_stats[\"corr_rel_mag_dir_inf_significant\"] = False\n",
    "\n",
    "            if len(rel_mag) >= 3 and len(info_change) >= 3:\n",
    "                corr_val = self.safe_correlation(rel_mag, info_change)\n",
    "                layer_stats[\"corr_rel_mag_info_change\"] = corr_val\n",
    "\n",
    "                # Add significance test for correlation\n",
    "                try:\n",
    "                    _, p_value = stats.pearsonr(rel_mag, info_change)\n",
    "                    layer_stats[\"corr_rel_mag_info_change_pvalue\"] = float(p_value)\n",
    "                    layer_stats[\"corr_rel_mag_info_change_significant\"] = p_value < 0.05\n",
    "                except:\n",
    "                    layer_stats[\"corr_rel_mag_info_change_pvalue\"] = 1.0\n",
    "                    layer_stats[\"corr_rel_mag_info_change_significant\"] = False\n",
    "\n",
    "            if len(dir_inf) >= 3 and len(info_change) >= 3:\n",
    "                corr_val = self.safe_correlation(dir_inf, info_change)\n",
    "                layer_stats[\"corr_dir_inf_info_change\"] = corr_val\n",
    "\n",
    "                # Add significance test for correlation\n",
    "                try:\n",
    "                    _, p_value = stats.pearsonr(dir_inf, info_change)\n",
    "                    layer_stats[\"corr_dir_inf_info_change_pvalue\"] = float(p_value)\n",
    "                    layer_stats[\"corr_dir_inf_info_change_significant\"] = p_value < 0.05\n",
    "                except:\n",
    "                    layer_stats[\"corr_dir_inf_info_change_pvalue\"] = 1.0\n",
    "                    layer_stats[\"corr_dir_inf_info_change_significant\"] = False\n",
    "\n",
    "            stats_results[\"by_layer\"][layer_idx] = layer_stats\n",
    "\n",
    "        overall_stats = {}\n",
    "\n",
    "        # Process overall relative magnitude\n",
    "        if len(all_rel_mag) >= 1:\n",
    "            overall_stats[\"relative_magnitude\"] = {\n",
    "                \"mean\": float(np.mean(all_rel_mag)),\n",
    "                \"median\": float(np.median(all_rel_mag)),\n",
    "                \"std\": float(np.std(all_rel_mag)) if len(all_rel_mag) > 1 else 0.0,\n",
    "                \"min\": float(np.min(all_rel_mag)),\n",
    "                \"max\": float(np.max(all_rel_mag))\n",
    "            }\n",
    "\n",
    "        # Process overall directional influence\n",
    "        if len(all_dir_inf) >= 1:\n",
    "            overall_stats[\"directional_influence\"] = {\n",
    "                \"mean\": float(np.mean(all_dir_inf)),\n",
    "                \"median\": float(np.median(all_dir_inf)),\n",
    "                \"std\": float(np.std(all_dir_inf)) if len(all_dir_inf) > 1 else 0.0,\n",
    "                \"min\": float(np.min(all_dir_inf)),\n",
    "                \"max\": float(np.max(all_dir_inf))\n",
    "            }\n",
    "\n",
    "        # Process overall information content change\n",
    "        if len(all_info_change) >= 1:\n",
    "            overall_stats[\"information_content_change\"] = {\n",
    "                \"mean\": float(np.mean(all_info_change)),\n",
    "                \"median\": float(np.median(all_info_change)),\n",
    "                \"std\": float(np.std(all_info_change)) if len(all_info_change) > 1 else 0.0,\n",
    "                \"min\": float(np.min(all_info_change)),\n",
    "                \"max\": float(np.max(all_info_change))\n",
    "            }\n",
    "\n",
    "        # Process overall reference token counts\n",
    "        if len(all_ref_counts) >= 1:\n",
    "            overall_stats[\"reference_token_count\"] = {\n",
    "                \"mean\": float(np.mean(all_ref_counts)),\n",
    "                \"median\": float(np.median(all_ref_counts)),\n",
    "                \"std\": float(np.std(all_ref_counts)) if len(all_ref_counts) > 1 else 0.0,\n",
    "                \"min\": float(np.min(all_ref_counts)),\n",
    "                \"max\": float(np.max(all_ref_counts))\n",
    "            }\n",
    "\n",
    "        # Calculate overall correlations with significance tests\n",
    "        if len(all_rel_mag) >= 3 and len(all_dir_inf) >= 3:\n",
    "            corr_val = self.safe_correlation(all_rel_mag, all_dir_inf)\n",
    "            overall_stats[\"corr_rel_mag_dir_inf\"] = corr_val\n",
    "\n",
    "            # significance test\n",
    "            try:\n",
    "                _, p_value = stats.pearsonr(all_rel_mag, all_dir_inf)\n",
    "                overall_stats[\"corr_rel_mag_dir_inf_pvalue\"] = float(p_value)\n",
    "                overall_stats[\"corr_rel_mag_dir_inf_significant\"] = p_value < 0.05\n",
    "            except:\n",
    "                overall_stats[\"corr_rel_mag_dir_inf_pvalue\"] = 1.0\n",
    "                overall_stats[\"corr_rel_mag_dir_inf_significant\"] = False\n",
    "\n",
    "        if len(all_rel_mag) >= 3 and len(all_info_change) >= 3:\n",
    "            corr_val = self.safe_correlation(all_rel_mag, all_info_change)\n",
    "            overall_stats[\"corr_rel_mag_info_change\"] = corr_val\n",
    "\n",
    "            # significance test\n",
    "            try:\n",
    "                _, p_value = stats.pearsonr(all_rel_mag, all_info_change)\n",
    "                overall_stats[\"corr_rel_mag_info_change_pvalue\"] = float(p_value)\n",
    "                overall_stats[\"corr_rel_mag_info_change_significant\"] = p_value < 0.05\n",
    "            except:\n",
    "                overall_stats[\"corr_rel_mag_info_change_pvalue\"] = 1.0\n",
    "                overall_stats[\"corr_rel_mag_info_change_significant\"] = False\n",
    "\n",
    "        if len(all_dir_inf) >= 3 and len(all_info_change) >= 3:\n",
    "            corr_val = self.safe_correlation(all_dir_inf, all_info_change)\n",
    "            overall_stats[\"corr_dir_inf_info_change\"] = corr_val\n",
    "\n",
    "            # significance test\n",
    "            try:\n",
    "                _, p_value = stats.pearsonr(all_dir_inf, all_info_change)\n",
    "                overall_stats[\"corr_dir_inf_info_change_pvalue\"] = float(p_value)\n",
    "                overall_stats[\"corr_dir_inf_info_change_significant\"] = p_value < 0.05\n",
    "            except:\n",
    "                overall_stats[\"corr_dir_inf_info_change_pvalue\"] = 1.0\n",
    "                overall_stats[\"corr_dir_inf_info_change_significant\"] = False\n",
    "\n",
    "        # Layer pattern analysis \n",
    "        layer_indices = sorted([int(idx) for idx in metric_collectors[\"relative_magnitude\"].keys() if metric_collectors[\"relative_magnitude\"][idx]])\n",
    "        if layer_indices and len(layer_indices) >= 2:\n",
    "            layer_evolution = {}\n",
    "\n",
    "            # Relative magnitude evolution\n",
    "            rel_mag_by_layer = [self.safe_mean(metric_collectors[\"relative_magnitude\"][str(idx)])\n",
    "                              for idx in layer_indices\n",
    "                              if metric_collectors[\"relative_magnitude\"][str(idx)]]\n",
    "\n",
    "            if len(rel_mag_by_layer) >= 2:\n",
    "                layer_evolution[\"relative_magnitude_trend\"] = self.safe_trend_analysis(\n",
    "                    layer_indices[:len(rel_mag_by_layer)], rel_mag_by_layer\n",
    "                )\n",
    "\n",
    "            # Directional influence evolution\n",
    "            dir_inf_by_layer = [self.safe_mean(metric_collectors[\"directional_influence\"][str(idx)])\n",
    "                              for idx in layer_indices\n",
    "                              if metric_collectors[\"directional_influence\"][str(idx)]]\n",
    "\n",
    "            if len(dir_inf_by_layer) >= 2:\n",
    "                layer_evolution[\"directional_influence_trend\"] = self.safe_trend_analysis(\n",
    "                    layer_indices[:len(dir_inf_by_layer)], dir_inf_by_layer\n",
    "                )\n",
    "\n",
    "            # Information content change evolution\n",
    "            info_change_by_layer = [self.safe_mean(metric_collectors[\"information_content_change\"][str(idx)])\n",
    "                                  for idx in layer_indices\n",
    "                                  if metric_collectors[\"information_content_change\"][str(idx)]]\n",
    "\n",
    "            if len(info_change_by_layer) >= 2:\n",
    "                layer_evolution[\"information_content_change_trend\"] = self.safe_trend_analysis(\n",
    "                    layer_indices[:len(info_change_by_layer)], info_change_by_layer\n",
    "                )\n",
    "\n",
    "            # Store layer evolution patterns\n",
    "            overall_stats[\"layer_evolution\"] = layer_evolution\n",
    "\n",
    "            # statistical test for early vs late layers comparison\n",
    "            self.add_layer_comparison_tests(layer_indices, metric_collectors, overall_stats)\n",
    "\n",
    "        stats_results[\"overall\"] = overall_stats\n",
    "\n",
    "        return stats_results\n",
    "\n",
    "    def add_layer_comparison_tests(self, layer_indices, metric_collectors, overall_stats):\n",
    "        \"\"\"\n",
    "        Add statistical tests to compare metrics between early and late layers.\n",
    "        Uses paired t-tests to determine if there are significant differences.\n",
    "\n",
    "        Args:\n",
    "            layer_indices: list of layer indices sorted in ascending order\n",
    "            metric_collectors: dictionary containing the collected metrics\n",
    "            overall_stats: dictionary to store the comparison results\n",
    "        \"\"\"\n",
    "        if len(layer_indices) < 4:  # Need at least 4 layers for meaningful comparison\n",
    "            return\n",
    "\n",
    "        early_layers = layer_indices[:len(layer_indices)//2]\n",
    "        late_layers = layer_indices[len(layer_indices)//2:]\n",
    "\n",
    "        layer_comparisons = {\n",
    "            \"early_vs_late\": {}\n",
    "        }\n",
    "\n",
    "        # Compare metrics between early and late layers\n",
    "        for metric_name in [\"relative_magnitude\", \"directional_influence\", \"information_content_change\"]:\n",
    "            if metric_name not in metric_collectors:\n",
    "                continue\n",
    "\n",
    "            # Collect early and late layer metrics\n",
    "            early_metrics = []\n",
    "            for layer_idx in early_layers:\n",
    "                layer_data = metric_collectors[metric_name].get(str(layer_idx), [])\n",
    "                # Filter out NaN and Inf values\n",
    "                layer_data = [v for v in layer_data if not np.isnan(v) and not np.isinf(v)]\n",
    "                if layer_data:\n",
    "                    early_metrics.append(self.safe_mean(layer_data))\n",
    "\n",
    "            late_metrics = []\n",
    "            for layer_idx in late_layers:\n",
    "                layer_data = metric_collectors[metric_name].get(str(layer_idx), [])\n",
    "                # Filter out NaN and Inf values\n",
    "                layer_data = [v for v in layer_data if not np.isnan(v) and not np.isinf(v)]\n",
    "                if layer_data:\n",
    "                    late_metrics.append(self.safe_mean(layer_data))\n",
    "\n",
    "            # Perform t-test if we have enough data\n",
    "            if len(early_metrics) >= 2 and len(late_metrics) >= 2:\n",
    "                try:\n",
    "                    # Independent samples t-test\n",
    "                    t_stat, p_value = stats.ttest_ind(early_metrics, late_metrics, equal_var=False)\n",
    "\n",
    "                    comparison_result = {\n",
    "                        \"early_mean\": float(np.mean(early_metrics)),\n",
    "                        \"late_mean\": float(np.mean(late_metrics)),\n",
    "                        \"difference\": float(np.mean(late_metrics) - np.mean(early_metrics)),\n",
    "                        \"t_statistic\": float(t_stat),\n",
    "                        \"p_value\": float(p_value),\n",
    "                        \"significant\": p_value < 0.05\n",
    "                    }\n",
    "\n",
    "                    layer_comparisons[\"early_vs_late\"][metric_name] = comparison_result\n",
    "\n",
    "                except Exception as e:\n",
    "                    # If t-test fails, store basic comparison without statistical test\n",
    "                    comparison_result = {\n",
    "                        \"early_mean\": float(np.mean(early_metrics)) if early_metrics else 0.0,\n",
    "                        \"late_mean\": float(np.mean(late_metrics)) if late_metrics else 0.0,\n",
    "                        \"difference\": float(np.mean(late_metrics) - np.mean(early_metrics)) if early_metrics and late_metrics else 0.0,\n",
    "                        \"error\": str(e)\n",
    "                    }\n",
    "\n",
    "                    layer_comparisons[\"early_vs_late\"][metric_name] = comparison_result\n",
    "\n",
    "        overall_stats[\"layer_comparisons\"] = layer_comparisons\n",
    "\n",
    "    def generate_statistics_report(self):\n",
    "        \"\"\"\n",
    "        Generate a simple text report with statistics, correlation values, and statistical tests.\n",
    "        Shows data from first layer, last layer, and two intermediate layers.\n",
    "        \"\"\"\n",
    "        if not self.results or \"statistics\" not in self.results:\n",
    "            return \"No statistics available. Run analyze_samples first.\"\n",
    "\n",
    "        stats_results = self.results[\"statistics\"]\n",
    "        successful_analyses = self.results.get(\"successful_analyses\", 0)\n",
    "\n",
    "        lines = []\n",
    "        lines.append(f\"REFERENCE POINT ANALYSIS FOR {self.model_name}\\n\")\n",
    "        lines.append(f\"Based on {successful_analyses} text samples\\n\")\n",
    "\n",
    "        lines.append(\"OVERALL STATISTICS\")\n",
    "        lines.append(\"=\" * 20)\n",
    "\n",
    "        overall = stats_results[\"overall\"]\n",
    "        if not overall:\n",
    "            lines.append(\"\\nNo overall statistics available.\")\n",
    "        else:\n",
    "            for metric_name in [\"relative_magnitude\", \"directional_influence\", \"information_content_change\", \"reference_token_count\"]:\n",
    "                if metric_name in overall:\n",
    "                    lines.append(f\"\\n{metric_name.replace('_', ' ').title()}:\")\n",
    "                    metric_stats = overall[metric_name]\n",
    "                    lines.append(f\"  Mean: {metric_stats['mean']:.4f}\")\n",
    "                    lines.append(f\"  Median: {metric_stats['median']:.4f}\")\n",
    "                    lines.append(f\"  Std Dev: {metric_stats['std']:.4f}\")\n",
    "                    lines.append(f\"  Range: {metric_stats['min']:.4f} to {metric_stats['max']:.4f}\")\n",
    "\n",
    "            # Correlations with significance tests\n",
    "            lines.append(\"\\nOverall Correlations:\")\n",
    "            corr_keys = [k for k in overall.keys() if k.startswith(\"corr_\") and not k.endswith(\"_pvalue\") and not k.endswith(\"_significant\")]\n",
    "            if corr_keys:\n",
    "                for corr_key in corr_keys:\n",
    "                    metric_names = corr_key.replace(\"corr_\", \"\").split(\"_\")\n",
    "                    metric_readable = \" vs. \".join([name.replace(\"_\", \" \").title() for name in metric_names])\n",
    "                    corr_value = overall[corr_key]\n",
    "\n",
    "                    sig_key = f\"{corr_key}_significant\"\n",
    "                    pval_key = f\"{corr_key}_pvalue\"\n",
    "\n",
    "                    if sig_key in overall and pval_key in overall:\n",
    "                        is_significant = overall[sig_key]\n",
    "                        p_value = overall[pval_key]\n",
    "                        sig_marker = \"* \" if is_significant else \"\"\n",
    "                        lines.append(f\"  {metric_readable}: {corr_value:.4f} {sig_marker}(p = {p_value:.4f})\")\n",
    "                    else:\n",
    "                        lines.append(f\"  {metric_readable}: {corr_value:.4f}\")\n",
    "            else:\n",
    "                lines.append(\"  No correlations available.\")\n",
    "\n",
    "            # Layer evolution patterns\n",
    "            if \"layer_evolution\" in overall:\n",
    "                lines.append(\"\\nLayer Evolution Patterns:\")\n",
    "                for trend_key, trend_data in overall[\"layer_evolution\"].items():\n",
    "                    metric_name = trend_key.replace(\"_trend\", \"\").replace(\"_\", \" \").title()\n",
    "                    lines.append(f\"  {metric_name}: {trend_data['pattern'].title()} (correlation: {trend_data['correlation']:.4f})\")\n",
    "\n",
    "            # Add early vs late layer comparison results\n",
    "            if \"layer_comparisons\" in overall and \"early_vs_late\" in overall[\"layer_comparisons\"]:\n",
    "                lines.append(\"\\nEarly vs. Late Layer Comparisons (t-tests):\")\n",
    "\n",
    "                comparisons = overall[\"layer_comparisons\"][\"early_vs_late\"]\n",
    "                for metric_name, comp_data in comparisons.items():\n",
    "                    metric_readable = metric_name.replace(\"_\", \" \").title()\n",
    "\n",
    "                    if \"significant\" in comp_data:\n",
    "                        sig_marker = \"* \" if comp_data[\"significant\"] else \"\"\n",
    "                        lines.append(f\"  {metric_readable}:\")\n",
    "                        lines.append(f\"    Early layers mean: {comp_data['early_mean']:.4f}\")\n",
    "                        lines.append(f\"    Late layers mean: {comp_data['late_mean']:.4f}\")\n",
    "                        lines.append(f\"    Difference: {comp_data['difference']:.4f} {sig_marker}\")\n",
    "                        lines.append(f\"    t-statistic: {comp_data['t_statistic']:.4f}, p-value: {comp_data['p_value']:.4f}\")\n",
    "                    else:\n",
    "                        lines.append(f\"  {metric_readable}: Insufficient data for statistical test\")\n",
    "\n",
    "            lines.append(\"\\nLAYER-SPECIFIC STATISTICS (select layers):\")\n",
    "\n",
    "            valid_layers = sorted([int(layer_idx) for layer_idx in stats_results[\"by_layer\"].keys()\n",
    "                                  if stats_results[\"by_layer\"][layer_idx]],\n",
    "                                  key=lambda x: int(x))\n",
    "\n",
    "            if not valid_layers:\n",
    "                lines.append(\"\\nNo layer-specific statistics available.\")\n",
    "            else:\n",
    "                # Select specific layers to report\n",
    "                num_layers = max(valid_layers) + 1  # +1 because layer indices are 0-based\n",
    "\n",
    "                # Choose layers to analyze (first, quarter, three-quarters, last)\n",
    "                first_layer = 0\n",
    "                quarter_layer = max(1, num_layers // 4)  \n",
    "                three_quarter_layer = max(2, (num_layers * 3) // 4) \n",
    "                last_layer = max(valid_layers)\n",
    "\n",
    "                selected_layers = sorted(list(set([first_layer, quarter_layer, three_quarter_layer, last_layer])))\n",
    "\n",
    "                selected_layers = [layer for layer in selected_layers if str(layer) in stats_results[\"by_layer\"]]\n",
    "\n",
    "                for layer_idx in selected_layers:\n",
    "                    layer_stats = stats_results[\"by_layer\"][str(layer_idx)]\n",
    "                    if not layer_stats:\n",
    "                        continue\n",
    "\n",
    "                    if layer_idx == first_layer:\n",
    "                        position_label = \"FIRST LAYER\"\n",
    "                    elif layer_idx == last_layer:\n",
    "                        position_label = \"LAST LAYER\"\n",
    "                    elif layer_idx == quarter_layer:\n",
    "                        position_label = \"QUARTER-DEPTH LAYER\"\n",
    "                    elif layer_idx == three_quarter_layer:\n",
    "                        position_label = \"THREE-QUARTER-DEPTH LAYER\"\n",
    "                    else:\n",
    "                        position_label = \"\"\n",
    "\n",
    "                    lines.append(f\"\\nLayer {layer_idx}: {position_label}\")\n",
    "\n",
    "                    for metric_name in [\"relative_magnitude\", \"directional_influence\", \"information_content_change\"]:\n",
    "                        if metric_name in layer_stats:\n",
    "                            metric_readable = metric_name.replace(\"_\", \" \").title()\n",
    "                            lines.append(f\"  {metric_readable} Mean: {layer_stats[metric_name]['mean']:.4f}\")\n",
    "\n",
    "                    corr_keys = [k for k in layer_stats.keys() if k.startswith(\"corr_\") and not k.endswith(\"_pvalue\") and not k.endswith(\"_significant\")]\n",
    "                    if corr_keys:\n",
    "                        lines.append(\"  Correlations:\")\n",
    "                        for corr_key in corr_keys:\n",
    "                            metric_names = corr_key.replace(\"corr_\", \"\").split(\"_\")\n",
    "                            metric_readable = \" vs. \".join([name.replace(\"_\", \" \").title() for name in metric_names])\n",
    "                            corr_value = layer_stats[corr_key]\n",
    "\n",
    "                            sig_key = f\"{corr_key}_significant\"\n",
    "                            pval_key = f\"{corr_key}_pvalue\"\n",
    "\n",
    "                            if sig_key in layer_stats and pval_key in layer_stats:\n",
    "                                is_significant = layer_stats[sig_key]\n",
    "                                p_value = layer_stats[pval_key]\n",
    "                                sig_marker = \"* \" if is_significant else \"\"\n",
    "                                lines.append(f\"    {metric_readable}: {corr_value:.4f} {sig_marker}(p = {p_value:.4f})\")\n",
    "                            else:\n",
    "                                lines.append(f\"    {metric_readable}: {corr_value:.4f}\")\n",
    "\n",
    "            lines.append(\"\\nKEY FINDINGS:\")\n",
    "\n",
    "            if not overall:\n",
    "                lines.append(\"- Not enough data to generate key findings.\")\n",
    "            else:\n",
    "                if \"relative_magnitude\" in overall:\n",
    "                    rel_mag = overall[\"relative_magnitude\"]\n",
    "                    if rel_mag[\"mean\"] > 0.5:\n",
    "                        lines.append(\"- Reference tokens have a STRONG influence on value transformations\")\n",
    "                    elif rel_mag[\"mean\"] > 0.3:\n",
    "                        lines.append(\"- Reference tokens have a MODERATE influence on value transformations\")\n",
    "                    else:\n",
    "                        lines.append(\"- Reference tokens have a WEAK influence on value transformations\")\n",
    "\n",
    "                if \"directional_influence\" in overall:\n",
    "                    dir_inf = overall[\"directional_influence\"]\n",
    "                    if dir_inf[\"mean\"] > 0.7:\n",
    "                        lines.append(\"- Reference tokens strongly ALIGN with the overall transformation direction\")\n",
    "                    elif dir_inf[\"mean\"] > 0.4:\n",
    "                        lines.append(\"- Reference tokens moderately align with the overall transformation direction\")\n",
    "                    else:\n",
    "                        lines.append(\"- Reference tokens contribute in directions ORTHOGONAL to the overall transformation\")\n",
    "\n",
    "                if \"layer_evolution\" in overall:\n",
    "                    layer_evo = overall[\"layer_evolution\"]\n",
    "\n",
    "                    if \"relative_magnitude_trend\" in layer_evo:\n",
    "                        rm_trend = layer_evo[\"relative_magnitude_trend\"]\n",
    "                        if rm_trend[\"pattern\"] == \"increasing\":\n",
    "                            lines.append(\"- Reference token influence INCREASES in deeper layers\")\n",
    "                        elif rm_trend[\"pattern\"] == \"decreasing\":\n",
    "                            lines.append(\"- Reference token influence DECREASES in deeper layers\")\n",
    "\n",
    "                    # Add layer comparison insights if we have both first and last layer\n",
    "                    selected_layers = sorted(list(set([first_layer, quarter_layer, three_quarter_layer, last_layer])))\n",
    "                    if first_layer in selected_layers and last_layer in selected_layers and first_layer != last_layer:\n",
    "                        try:\n",
    "                            first_rm = stats_results[\"by_layer\"][str(first_layer)][\"relative_magnitude\"][\"mean\"]\n",
    "                            last_rm = stats_results[\"by_layer\"][str(last_layer)][\"relative_magnitude\"][\"mean\"]\n",
    "\n",
    "                            rm_diff = last_rm - first_rm\n",
    "                            if abs(rm_diff) > 0.1:  # Significant difference\n",
    "                                if rm_diff > 0:\n",
    "                                    lines.append(f\"- Reference influence GROWS by {rm_diff:.2f} from first to last layer\")\n",
    "                                else:\n",
    "                                    lines.append(f\"- Reference influence DECREASES by {abs(rm_diff):.2f} from first to last layer\")\n",
    "                        except (KeyError, TypeError):\n",
    "                            pass  \n",
    "\n",
    "                if \"layer_comparisons\" in overall and \"early_vs_late\" in overall[\"layer_comparisons\"]:\n",
    "                    comparisons = overall[\"layer_comparisons\"][\"early_vs_late\"]\n",
    "\n",
    "                    for metric_name, comp_data in comparisons.items():\n",
    "                        if \"significant\" in comp_data and comp_data[\"significant\"]:\n",
    "                            metric_readable = metric_name.replace(\"_\", \" \").title()\n",
    "                            diff = comp_data[\"difference\"]\n",
    "                            direction = \"INCREASES\" if diff > 0 else \"DECREASES\"\n",
    "                            lines.append(f\"- {metric_readable} SIGNIFICANTLY {direction} from early to late layers (p < 0.05)\")\n",
    "\n",
    "            lines.append(\"\\nNote: * indicates statistical significance at p < 0.05\")\n",
    "\n",
    "            report_path = os.path.join(self.output_dir, \"reference_point_analysis.txt\")\n",
    "            with open(report_path, 'w') as f:\n",
    "                f.write('\\n'.join(lines))\n",
    "\n",
    "            print(f\"Report saved to {report_path}\")\n",
    "            return '\\n'.join(lines)\n",
    "\n",
    "    def run_analysis(self, texts=None):\n",
    "        \"\"\"\n",
    "        Run the complete reference point analysis pipeline.\n",
    "        \"\"\"\n",
    "        start_time = time.time()\n",
    "\n",
    "        if self.model is None:\n",
    "            self.load_model()\n",
    "\n",
    "            if self.model is None:\n",
    "                return \"Model loading failed. Cannot continue analysis.\"\n",
    "\n",
    "        if texts is None or not texts:\n",
    "            texts = [\n",
    "                \"The concept of attention in transformer models relates to how tokens interact.\",\n",
    "                \"In deep learning, reference points help establish coordinate systems for representation.\",\n",
    "                \"Attention mechanisms create dynamic connections between tokens in a sequence.\",\n",
    "                \"Self-attention allows each token to gather information from all other tokens.\"\n",
    "            ]\n",
    "\n",
    "        stats_results = self.analyze_samples(texts)\n",
    "\n",
    "        if stats_results:\n",
    "            report = self.generate_statistics_report()\n",
    "        else:\n",
    "            report = \"Analysis did not produce valid statistics.\"\n",
    "\n",
    "        total_time = time.time() - start_time\n",
    "        print(f\"Analysis completed in {total_time/60:.2f} minutes\")\n",
    "\n",
    "        return report\n",
    "\n",
    "    def cleanup(self):\n",
    "        \"\"\"Clean up resources.\"\"\"\n",
    "        if self.model is not None:\n",
    "            self.model = self.model.to(\"cpu\")\n",
    "            del self.model\n",
    "            self.model = None\n",
    "\n",
    "        if self.tokenizer is not None:\n",
    "            del self.tokenizer\n",
    "            self.tokenizer = None\n",
    "\n",
    "        self.hidden_states = None\n",
    "        self.attention_matrices = None\n",
    "\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        print(\"Resources cleaned up\")\n",
    "\n",
    "\n",
    "def get_sample_texts_from_dataset(dataset_path, n_samples=500):\n",
    "    \"\"\"\n",
    "    Extract sample texts from a dataset for analysis.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        data = pd.read_csv(dataset_path)\n",
    "        print(f\"Loaded dataset with {len(data)} rows\")\n",
    "\n",
    "        if 'text' not in data.columns:\n",
    "            potential_text_columns = ['content', 'sentence', 'document', 'passage']\n",
    "            found_column = None\n",
    "\n",
    "            for col in potential_text_columns:\n",
    "                if col in data.columns:\n",
    "                    found_column = col\n",
    "                    break\n",
    "\n",
    "            if found_column:\n",
    "                print(f\"No 'text' column found, using '{found_column}' instead\")\n",
    "            else:\n",
    "                print(\"Error: No suitable text column found in dataset\")\n",
    "                return []\n",
    "        else:\n",
    "            found_column = 'text'\n",
    "\n",
    "        if len(data) > n_samples:\n",
    "            samples = data.sample(n_samples)\n",
    "        else:\n",
    "            samples = data\n",
    "\n",
    "        texts = samples[found_column].tolist()\n",
    "\n",
    "        texts = [t for t in texts if t is not None and str(t).strip()]\n",
    "\n",
    "        return texts\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset: {e}\")\n",
    "        traceback.print_exc()\n",
    "        return []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53396c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main():\n",
    "    \"\"\"Run the Reference Point Analysis.\"\"\"\n",
    "    try:\n",
    "        from google.colab import drive\n",
    "        # Mount Google Drive if in Colab\n",
    "        drive.mount('/content/drive')\n",
    "        is_colab = True\n",
    "    except ImportError:\n",
    "        is_colab = False\n",
    "        print(\"Not running in Google Colab, skipping drive mount\")\n",
    "\n",
    "    model_name = \"meta-llama/llama-3.2-3B\"  \n",
    "\n",
    "    if is_colab:\n",
    "        dataset_path = \"/content/drive/MyDrive/wiki_dataset_position.csv\"  \n",
    "        output_dir = f\"/content/drive/MyDrive/Sink/reference_analysis/{model_name}\"\n",
    "    else:\n",
    "        dataset_path = \"./dataset.csv\"\n",
    "        output_dir = f\"./reference_analysis_{model_name.replace('/', '_')}\"\n",
    "\n",
    "    analyzer = ReferencePointAnalysis(\n",
    "        model_name=model_name,\n",
    "        output_dir=output_dir\n",
    "    )\n",
    "    analyzer.debug = False\n",
    "\n",
    "    texts = get_sample_texts_from_dataset(dataset_path, n_samples=500)  \n",
    "\n",
    "    if not texts:\n",
    "        texts = [\n",
    "            \"The concept of attention in transformer models relates to how tokens interact.\",\n",
    "            \"In deep learning, reference points help establish coordinate systems for representation.\",\n",
    "            \"Attention mechanisms create dynamic connections between tokens in a sequence.\",\n",
    "            \"Self-attention allows each token to gather information from all other tokens.\"\n",
    "        ]\n",
    "\n",
    "    try:\n",
    "        print(f\"Running analysis with {len(texts)} text samples\")\n",
    "\n",
    "        analysis_report = analyzer.run_analysis(texts=texts)\n",
    "\n",
    "        print(\"\\nREFERENCE POINT ANALYSIS SUMMARY:\")\n",
    "        print(\"==========================\")\n",
    "\n",
    "        print(analysis_report)\n",
    "\n",
    "        print(\"\\nAnalysis completed successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Analysis error: {e}\")\n",
    "        traceback.print_exc()\n",
    "    finally:\n",
    "        analyzer.cleanup()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
